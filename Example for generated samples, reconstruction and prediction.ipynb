{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as P\n",
    "import torchvision\n",
    "\n",
    "# Import stuff\n",
    "import utils\n",
    "import losses\n",
    "import layers as layer\n",
    "#import train_fns\n",
    "import train_fns\n",
    "from sync_batchnorm import patch_replication_callback\n",
    "\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name   = 'weights'\n",
    "logs_name      = 'logs'\n",
    "samples_name   = ''\n",
    "\n",
    "model_name  = 'BigGAN_MPCC'\n",
    "\n",
    "model_path  = '%s/%s'%(weights_name, model_name)\n",
    "logs_path   = '%s/%s'%(logs_name,    model_name)\n",
    "\n",
    "\n",
    "config_path = '%s/metalog.txt'%logs_path\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "file = open(config_path, 'r')\n",
    "all_file = file.read()\n",
    "fs1 = all_file.find('{')\n",
    "fs2 = all_file.find('}')\n",
    "config = all_file[fs1:fs2+1]\n",
    "import ast\n",
    "config = config.replace(\", 'G_activation': ReLU()\" , \"\")\n",
    "config = config.replace(\", 'D_activation': ReLU()\" , \"\")\n",
    "config = ast.literal_eval(config)\n",
    "\n",
    "config['samples_root'] = 'samples_test'\n",
    "config['weights_root'] = weights_name\n",
    "config['concat']       = True\n",
    "config['model']        = 'BigGAN_MPCC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param count for Gs initialized parameters: 9360131\n",
      "Param count for Ds initialized parameters: 9456769\n",
      "16\n",
      "2\n",
      "Param count for Ds initialized parameters: 17615872\n",
      "Loading weights from weights/BigGAN_MPCC...\n"
     ]
    }
   ],
   "source": [
    "model = __import__(config['model'])\n",
    "utils.seed_rng(config['seed'])\n",
    "# Prepare root folders if necessary\n",
    "utils.prepare_root(config)\n",
    "\n",
    "G = model.Generator(**config).to(device)\n",
    "D = model.Discriminator(**config).to(device)\n",
    "if config['is_encoder']:\n",
    "    E = model.Encoder(**{**config, 'D': D}).to(device)\n",
    "Prior  = layer.Prior(**config).to(device)   \n",
    "GE = model.G_E(G,E,Prior)\n",
    "\n",
    "utils.load_weights(G, None, '',\n",
    "                config['weights_root'], model_name, \n",
    "                config['load_weights'] if config['load_weights'] else None,\n",
    "                G if config['ema'] else None, \n",
    "                E = None if not config['is_encoder'] else E,\n",
    "                Prior = Prior if not config['prior_type'] == 'default' else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate_stats = True\n",
    "if accumulate_stats:\n",
    "    utils.accumulate_standing_stats(G,\n",
    "                           Prior, config['n_classes'],\n",
    "                           config['num_standing_accumulations'])\n",
    "sample = functools.partial(utils.sample, G=G, Prior = Prior, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.sample_sheet(G, Prior,\n",
    "                    classes_per_sheet = 10,\n",
    "                     #classes_per_sheet=utils.classes_per_sheet_dict[config['dataset']],\n",
    "                     num_classes=config['n_classes'],\n",
    "                     samples_per_class=7, parallel=config['parallel'],\n",
    "                     samples_root=config['samples_root'],\n",
    "                     experiment_name=model_name,\n",
    "                     folder_number= 4  , transpose = True, num_rep = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset root location data/cifar\n",
      "Data will not be augmented...\n",
      "Files already downloaded and verified\n",
      "(50000, 3072)\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "D_batch_size = (config['batch_size'] * config['num_D_steps'] * config['num_D_accumulations'])\n",
    "config_aux = config.copy()\n",
    "config_aux['augment'] = False\n",
    "dataloader_noaug = utils.get_data_loaders(**{**config_aux, 'batch_size': D_batch_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain reconstruction sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reconstruction_sheet(GE,\n",
    "                         classes_per_sheet = 6,\n",
    "                        #classes_per_sheet=utils.classes_per_sheet_dict[config['dataset']],\n",
    "                         num_classes = config['n_classes'], \n",
    "                         #samples_per_class = 10, \n",
    "                         samples_per_class = 4, \n",
    "                         parallel = config['parallel'],\n",
    "                         samples_root= config['samples_root'],\n",
    "                         experiment_name = model_name,\n",
    "                         folder_number = 4, dataloader= dataloader_noaug, device = device,\n",
    "                                   D_fp16 = config['D_fp16'], config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering accuracy  0.68755\n"
     ]
    }
   ],
   "source": [
    "config['is_not_rec'] = False\n",
    "test_acc, _,  error_rec = train_fns.test_accuracy(GE, dataloader_noaug, device, config['D_fp16'], config)\n",
    "print(\"Clustering accuracy \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy \"as usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering accuracy  0.6875666666666667\n"
     ]
    }
   ],
   "source": [
    "def obtain_cluster_transformation(Y_pred, Y):\n",
    "    D = int(np.max((np.max(Y_pred), np.max(Y)))+1)\n",
    "    w = np.zeros((D,D))\n",
    "    for i in range(len(Y_pred)):\n",
    "        w[int(Y_pred[i]), int(Y[i])] += 1\n",
    "    #print(w)\n",
    "    return w.argmax(1)\n",
    "\n",
    "total_y, total_y_pred, mse_norm = train_fns.test_accuracy(GE, dataloader_noaug, device, config['D_fp16'], config, obtain_y = True)\n",
    "transf = obtain_cluster_transformation(total_y_pred, total_y)\n",
    "print(\"Clustering accuracy \", np.mean(transf[total_y_pred] == total_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
